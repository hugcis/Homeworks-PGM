{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_data(fname):\n",
    "    df = pd.read_csv(fname, delimiter='\\t')\n",
    "    return df.values[:, :-1], df.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def plot_data(frontier, fname, method, X, y):\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    fig.tight_layout()\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y)\n",
    "    ax.plot(np.linspace(X[:, 0].min(), X[:, 0].max()), \n",
    "            frontier(np.linspace(X[:, 0].min(), X[:, 0].max())), 'k')\n",
    "    wi = X[:, 0].max() - X[:, 0].min()\n",
    "    he = X[:, 1].max() - X[:, 1].min()\n",
    "    ax.set_xlim(X[:, 0].min()-0.1*wi, X[:, 0].max()+0.1*wi)\n",
    "    ax.set_ylim(X[:, 1].min()-0.1*he, X[:, 1].max()+0.1*he)\n",
    "    plt.title(method)\n",
    "    plt.savefig('{}_{}.pdf'.format(fname, method))\n",
    "    plt.close()\n",
    "    \n",
    "def plot_mesh_data(frontier, fname, method, X, y):\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    fig.tight_layout()\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y)\n",
    "    \n",
    "    wi = X[:, 0].max() - X[:, 0].min()\n",
    "    he = X[:, 1].max() - X[:, 1].min()\n",
    "    \n",
    "    x = np.linspace(X[:, 0].min()-0.1*wi, X[:, 0].max()+0.1*wi)\n",
    "    y = np.linspace(X[:, 1].min()-0.1*he, X[:, 1].max()+0.1*he)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    \n",
    "    ax.contour(x, y, frontier(x, y), [0.5], colors='k')\n",
    "\n",
    "    ax.set_xlim(X[:, 0].min()-0.1*wi, X[:, 0].max()+0.1*wi)\n",
    "    ax.set_ylim(X[:, 1].min()-0.1*he, X[:, 1].max()+0.1*he)\n",
    "    plt.title(method)\n",
    "    plt.savefig('{}_{}.pdf'.format(fname, method))\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA_model:\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.pi = np.sum(y==1)/len(y)\n",
    "        self.mu1 = np.mean(X[y==1], axis=0)\n",
    "        self.mu2 = np.mean(X[y==0], axis=0)\n",
    "        \n",
    "        sigma = np.cov(X[y==1].T)*np.sum(y==1)/len(y) + np.cov(X[y==0].T)*np.sum(y==0)/len(y)\n",
    "        self.sigma_inv = np.linalg.inv(sigma)\n",
    "        \n",
    "        self.a = np.log(self.pi/(1-self.pi)) + (1/2)*(self.mu2.T.dot(self.sigma_inv).dot(self.mu2) - \n",
    "                                                      self.mu1.T.dot(self.sigma_inv).dot(self.mu1))\n",
    "        self.b = (self.mu1 - self.mu2).T.dot(self.sigma_inv)\n",
    "        \n",
    "    def compute_frontier(self): \n",
    "\n",
    "        def frontier(x1):\n",
    "            return (-self.b[0]/self.b[1]) * x1 + self.a/self.b[1]\n",
    "        \n",
    "        return frontier\n",
    "        \n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return sigmoid(self.a + self.b.dot(X.T))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X) > 0.5\n",
    "        \n",
    "    def compute_misclassif_error(self, X, y):\n",
    "        return np.sum(self.predict(X) != y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QDA_model:\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.pi = np.sum(y==1)/len(y)\n",
    "        self.mu1 = np.mean(X[y==1], axis=0)\n",
    "        self.mu2 = np.mean(X[y==0], axis=0)\n",
    "        \n",
    "        sigma1 = np.cov(X[y==1].T)\n",
    "        sigma2 = np.cov(X[y==0].T)\n",
    "        self.sigma1_inv = np.linalg.inv(sigma1)\n",
    "        self.sigma2_inv = np.linalg.inv(sigma2)\n",
    "        \n",
    "        self.a = np.log(self.pi/(1-self.pi)) + (1/2)*(self.mu2.T.dot(self.sigma2_inv).dot(self.mu2) - \n",
    "                                            self.mu1.T.dot(self.sigma1_inv).dot(self.mu1))\n",
    "        self.b = self.mu1.T.dot(self.sigma1_inv) - self.mu2.T.dot(self.sigma2_inv)\n",
    "        \n",
    "    def compute_frontier(self): \n",
    "\n",
    "        def frontier(x1, x2):\n",
    "            interm = np.concatenate((x1[:, :, np.newaxis], x2[:, :, np.newaxis]), axis=2).reshape(-1, 2)\n",
    "            return self.predict_proba(interm).reshape(x1.shape)\n",
    "        \n",
    "        return frontier\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return sigmoid(self.a + self.b.dot(X.T) + \n",
    "                       (1/2)*np.sum(X.dot(self.sigma2_inv-self.sigma1_inv)*X, axis=1))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X) > 0.5\n",
    "        \n",
    "    def compute_misclassif_error(self, X, y):\n",
    "        return np.sum(self.predict(X) != y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logistic:\n",
    "    def __init__(self, reg=0):\n",
    "        self.reg=reg\n",
    "    \n",
    "    def fit(self, X, y, tol=1e-4):\n",
    "        X = np.concatenate((np.ones_like(X[:, 0])[:, np.newaxis], X), axis=1)\n",
    "        start=True\n",
    "        w = np.zeros(X[0, :].T.shape)\n",
    "        itern = 0\n",
    "        if start:\n",
    "            w_new = w - 2*tol\n",
    "        \n",
    "        while np.linalg.norm(w_new - w) > tol:# and itern < 1000:\n",
    "            w = w_new.copy()\n",
    "            eta = sigmoid(w.dot(X.T))\n",
    "            gradl = X.T.dot(y-eta)\n",
    "            Hl = -X.T.dot(np.diag(eta*(1-eta))).dot(X)\n",
    "            w_new = w - 0.01*np.linalg.inv(Hl + self.reg*np.identity(Hl.shape[0])).dot(gradl) #\n",
    "            \n",
    "            itern += 1\n",
    "            if itern%1000 == 0: print(w)\n",
    "            #print(w, eta, gradl, Hl)\n",
    "            #break\n",
    "        self.w = w_new\n",
    "        \n",
    "    def compute_frontier(self): \n",
    "\n",
    "        def frontier(x1):\n",
    "            return (1/self.w[2])*(-self.w[1] * x1 - self.w[0])\n",
    "        return frontier\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        X = np.concatenate((np.ones_like(X[:, 0])[:, np.newaxis], X), axis=1)\n",
    "        return sigmoid(self.w.dot(X.T))\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X) > 0.5\n",
    "        \n",
    "    def compute_misclassif_error(self, X, y):\n",
    "        return np.sum(self.predict(X) != y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def fit(self, X, y):\n",
    "        X = np.concatenate((np.ones_like(X[:, 0])[:, np.newaxis], X), axis=1)\n",
    "        self.w = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "        \n",
    "    def compute_frontier(self): \n",
    "\n",
    "        def frontier(x1):\n",
    "            return (1/self.w[2])*(-self.w[1] * x1 + 0.5 - self.w[0])\n",
    "        \n",
    "        return frontier\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = np.concatenate((np.ones_like(X[:, 0])[:, np.newaxis], X), axis=1)\n",
    "        return self.w.dot(X.T)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X) > 0.5\n",
    "        \n",
    "    def compute_misclassif_error(self, X, y):\n",
    "        return np.sum(self.predict(X) != y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3542169be046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reg' is not defined"
     ]
    }
   ],
   "source": [
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classificationA\n",
      "LDA Train Error: 0.0134228188\n",
      "LDA Test Error: 0.0206804536\n",
      "\n",
      "[ -13.85898798  -80.85535669 -139.55936297]\n",
      "[ -59.23576458 -355.95740408 -616.43986206]\n",
      "[ -104.53911804  -630.51749297 -1092.32756961]\n",
      "[ -149.84248379  -905.07765223 -1568.21539316]\n",
      "[ -191.61639924 -1137.15534938 -1976.17879187]\n",
      "Logistic Regression Train Error: 0.0000000000\n",
      "Logistic Regression Test Error: 0.0353569046\n",
      "\n",
      "Linear Regression Train Error: 0.0134228188\n",
      "Linear Regression Test Error: 0.0206804536\n",
      "\n",
      "QDA Train Error: 0.0067\n",
      "QDA Test Error: 0.0193\n",
      "\n",
      "\n",
      "classificationB\n",
      "LDA Train Error: 0.0301003344\n",
      "LDA Test Error: 0.0415207604\n",
      "\n",
      "Logistic Regression Train Error: 0.0200668896\n",
      "Logistic Regression Test Error: 0.0435217609\n",
      "\n",
      "Linear Regression Train Error: 0.0301003344\n",
      "Linear Regression Test Error: 0.0415207604\n",
      "\n",
      "QDA Train Error: 0.0234\n",
      "QDA Test Error: 0.0235\n",
      "\n",
      "\n",
      "classificationC\n",
      "LDA Train Error: 0.0551378446\n",
      "LDA Test Error: 0.0420140047\n",
      "\n",
      "Logistic Regression Train Error: 0.0401002506\n",
      "Logistic Regression Test Error: 0.0226742247\n",
      "\n",
      "Linear Regression Train Error: 0.0551378446\n",
      "Linear Regression Test Error: 0.0423474491\n",
      "\n",
      "QDA Train Error: 0.0526\n",
      "QDA Test Error: 0.0403\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in ['classificationA', 'classificationB', 'classificationC']:\n",
    "    X, y = open_data('classification_data_HWK1/{}.train'.format(name))\n",
    "    X_test, y_test = open_data('classification_data_HWK1/{}.test'.format(name))\n",
    "    print(name)\n",
    "    \n",
    "    ## LDA\n",
    "    lda = LDA_model()\n",
    "    lda.fit(X, y)\n",
    "    plot_data(lda.compute_frontier(), name, 'lda', X, y)\n",
    "    \n",
    "    print(\"LDA Train Error: {:.10f}\".format(lda.compute_misclassif_error(X, y)))\n",
    "    print(\"LDA Test Error: {:.10f}\\n\".format(lda.compute_misclassif_error(X_test, y_test)))\n",
    "    \n",
    "    ## Logistic Regression\n",
    "    logistic = Logistic(reg=0)\n",
    "    logistic.fit(X, y)\n",
    "    plot_data(logistic.compute_frontier(), name, 'logistic', X, y)\n",
    "    \n",
    "    print(\"Logistic Regression Train Error: {:.10f}\".format(logistic.compute_misclassif_error(X, y)))\n",
    "    print(\"Logistic Regression Test Error: {:.10f}\\n\".format(logistic.compute_misclassif_error(X_test, y_test)))\n",
    "    \n",
    "    ## Linear Regression\n",
    "    linear = LinearRegression()\n",
    "    linear.fit(X, y)\n",
    "    plot_data(linear.compute_frontier(), name, 'linear', X, y)\n",
    "    \n",
    "    print(\"Linear Regression Train Error: {:.10f}\".format(linear.compute_misclassif_error(X, y)))\n",
    "    print(\"Linear Regression Test Error: {:.10f}\\n\".format(linear.compute_misclassif_error(X_test, y_test)))\n",
    "    \n",
    "    ## QDA Regression\n",
    "    qda = QDA_model()\n",
    "    qda.fit(X, y)\n",
    "    plot_mesh_data(qda.compute_frontier(), name, 'qda', X, y)\n",
    "    \n",
    "    print(\"QDA Train Error: {:.4f}\".format(qda.compute_misclassif_error(X, y)))\n",
    "    print(\"QDA Test Error: {:.4f}\\n\".format(qda.compute_misclassif_error(X_test, y_test)))\n",
    "    \n",
    "    # Generate the error tables\n",
    "    with open(name+'_table.txt', 'w') as f:\n",
    "        f.write(\"\"\"\n",
    "    \\\\begin{{tabular}}{{c|cccc}}\n",
    "    Method & LDA & Logistic & Linear & QDA \\\\\\\\\n",
    "    \\hline\n",
    "    Train Error & {:.4f} & {:.4f} & {:.4f} & {:.4f} \\\\\\\\\n",
    "    \\hline\n",
    "    Test Error & {:.4f} & {:.4f} & {:.4f} & {:.4f} \\\\\\\\\n",
    "    \\\\end{{tabular}}\"\"\".format(\n",
    "        lda.compute_misclassif_error(X, y),\n",
    "        logistic.compute_misclassif_error(X, y),\n",
    "        linear.compute_misclassif_error(X, y),\n",
    "        qda.compute_misclassif_error(X, y),\n",
    "        lda.compute_misclassif_error(X_test, y_test),\n",
    "        logistic.compute_misclassif_error(X_test, y_test),\n",
    "        linear.compute_misclassif_error(X_test, y_test),\n",
    "        qda.compute_misclassif_error(X_test, y_test)))\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
